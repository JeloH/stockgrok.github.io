<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <title>Stockgrok Design</title>

    <!--To-do: Add favicon-->
    <link rel="icon" type="image/png" href="img/logo.png">

    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" href="scss/style.css">
    <!-- jQuery -->
    <script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
    <!-- Latest compiled and minified JavaScript -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
    <script src="js/script.js" async></script>
    <!--    </div>-->



</head>


<div id="nav">

</div>

<nav role="navigation">
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="index.html">Stockgrok</a>
        </div>
        <div class="navbar-header navbar-right">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="product.html">Product</a>
            <a class="navbar-brand" href="research.html">Research</a>
            <a class="navbar-brand active" href="design.html">Design</a>
            <a class="navbar-brand" href="next-steps.html">Opportunities</a>
            <a class="navbar-brand" href="team-b7g.html">Team b7g</a>
        </div>
    </div>
</nav>

<body>

    <div class="container-div" role="main" id="content">
        <div class="row skip-overview">
            <div class="col-sm-8 col-sm-offset-2">
                <h1 tabindex="0">Our Design Process</h1>

                <p>
                    After the research phase of our project, we shifted gears towards product design. The first step involved generating as many ideas as possible, accomplished by annotating our affinity diagram. We voted on the most promising ideas, and plotted them on a matrix that addressed the difficulty and impact of each idea. Twelve of these ideas were rapidly prototyped by the team, and tested with employees at Bloomberg. In the ensuing iterative design phase, we prototyped and tested three different modes of navigation to sonified data and relevant spoken details. We user-tested our prototypes with people with visual impairments, and found that a keyboard system made the most sense for the existing financial expert workflow. We also found that we needed to focus on providing context to price history, regardless of the chart being explored. We decided to build a web-based final product that could easily integrate into existing systems, or stand alone. We user-tested our final product with both people with visual impairment and sighted finance experts, and found that both were able to pick up on nonvisual cues about the changing trends in a security’s price history.

                </p>

                <ol class="breadcrumb">

                    <li><a href="#ideagen">Idea Generation</a></li>
                    <span class="glyphicon glyphicon-chevron-right"></span>
                    <li><a href="#rapidp">Rapid Prototyping</a></li>
                    <span class="glyphicon glyphicon-chevron-right"></span>
                    <li><a href="#itdes">Iterative Design</a></li>
                    <span class="glyphicon glyphicon-chevron-right"></span>
                    <li><a href="#stockgrok" class="highlight">Stockgrok</a></li>
                </ol>
            </div>
        </div>
    </div>
    <div class="row sec-head" id="ideagen">
        <div class="col-sm-8 col-sm-offset-2">
            <h2>Idea Generation</h2>

        </div>
    </div>



    <div class="row">
        <div>
            <div class="col-sm-8 col-sm-offset-2">
                <p tabindex="0" class="sec-subhead">After four months of research, we had so many ideas we wanted to get down on paper and try out. We began with the process of “walking the wall,” annotating our affinity diagram with design ideas, questions, and breakdowns. We voted on our most promising ideas as a group, and put them on an impact/feasibility matrix to better understand which ideas we could make happen, and how powerful they might be.
                </p>
            </div>
        </div>
        <section>
            <div class="col-sm-8 col-sm-offset-2">
                <h3>Generating and narrowing down design ideas</h3>
                <p tabindex="0" class="newspaper">
                    For our first foray into the design process, we “walked the wall.” In walking the wall, the entire group, first silently, then with conversation, went through the affinity diagram in depth and write design ideas, questions, and breakdowns we notice from the organized clusters. In narrowing down from our large list of design directions to a more manageable set we planned to prototype, we plotted the most promising ideas on a two-by-two matrix, using our best judgment as to the feasibility of building the idea, as well as the impact it could have on the workflows of people with visual impairments.
                </p>
            </div>



        </section>
        <section>
            <div class="col-sm-4 col-sm-offset-2">
                <img src="img/design-ideas.jpeg" alt="Three long white sheets with a white label on top that says 'Design Ideas.' The first sheet lists dozens of design ideas, the second sheet lists 'breakdowns', and the third sheet lists 'questions.' Text too small to read." class="img-responsive">
                <figcaption class="caption">Many of our ideas, questions, and breakdowns</figcaption>
            </div>
            <div class="col-sm-4">
                <img src="img/narrow-matrix.png" alt="This is a picture of the impact/feasibility matrix. Low impact ideas are on the bottom, high impact ideas are at the top, low difficulty ideas are on the left, and high difficulty ideas are on the right. The ideas with the highest impact include a conversational user interface and a querying language to ask questions about security charts. Text too small to read." class="img-responsive">
                <figcaption class="caption">Prioritizing our design ideas</figcaption>
            </div>

        </section>

    </div>

    <div class="row sec-head" id="rapidp">
        <div class="col-sm-8 col-sm-offset-2">
            <h2>Rapid Prototyping</h2>

        </div>
    </div>



    <div class="row">
        <div>
            <div class="col-sm-8 col-sm-offset-2">
                <p tabindex="0" class="sec-subhead">Once we had narrowed down our list of ideas to explore, we did an early round of quick prototypes. Rapid prototyping is a way of quickly testing ideas at a low fidelity and low cost level. Often constructed using paper and pencil, this stage of prototyping is useful to get quick feedback on the feasibility and usability of ideas. In our case, since we were primarily dealing with non-screen-based systems, we used the “Wizard of Oz” approach to many of the prototypes; in other words, we would play the role of the computer to simulate more complex interactions with a system. Most of these were then tested with sighted employees at Bloomberg to work out basic usability issues and better understand people’s expectations of our systems. We learned a lot about the infeasibility of some of our ideas, but were happy with our findings with regards to sonification and navigation methods.

                </p>
            </div>
        </div>
        <section>
            <div class="col-sm-8 col-sm-offset-2">
                <h3>Testing early prototypes for usability, feasibility, and desirability</h3>
            </div>
        </section>
        <section>
            <div class="col-sm-8 col-sm-offset-2 newspaper">
                <p tabindex="0">
                    We tested our prototypes with sighted employees at Bloomberg. It made sense at this stage to not worry about testing with people with visual impairments, as our goals at this point were to understand the feasibility of ideas, get a better hold of what kinds of expectations people would have of such systems, and work out early usability issues. We felt that it would be best to wait for higher fidelity prototypes before testing with people with visual impairments given our time constraints and budget.
                </p>
                <p>
                    Each prototype taught us something new. For example, we explored conversational user interfaces (CUIs). In this prototype, there was a big mismatch between what we felt we could provide (“what is the price of Google stock?”) and what users expected we could provide (“compare Apple and Google stock.”) Another promising prototype that subsequently fell into the infeasible category was generating crowdsourced or machine learning descriptions of charts. We learned that the technology isn’t really there, from an ML perspective, and that crowdsourcing won’t work well, especially when taking into account our research insight, “People who help me are interfaces, too.” There was simply no way to determine if a description was accurate.
                </p>

            </div>
        </section>
        <section>
            <div class="col-sm-8 col-sm-offset-2 newspaper3">
                <img src="img/graphgeoboardandrubberbands.jpg" style="margin-top:0px !important;" alt="A man has holds a yellow board with pegs. Rubber bands are wrapped around several pegs forming the zig zagging line of a chart." class="img-responsive">
                <figcaption class="caption">A tactile chart with pegs and rubber bands</figcaption>
                <img src="img/early-prototype-foamcore.JPG" alt="White foamcore with a grid of holes, with a diagonal line filled in with straws" class="img-responsive">
                <figcaption class="caption">A tactile chart with discrete points</figcaption>
                <img src="img/haptic.png" alt="A woman taps another woman on the back." class="img-responsive">
                <figcaption class="caption">A simulation of a haptic system</figcaption>
            </div>
        </section>
        <section>
            <div class="col-sm-8 col-sm-offset-2 newspaper">

                <p>
                    Finally, we explored touch-based interactions. We received very positive feedback about these prototypes, but upon exploring technical implementation, we realized that our examples were very basic, and the cost to provide dynamic, real-time tactile feedback would be prohibitively expensive. Not all of our prototypes were dead-ends, however. We explored using pitch to convey different values within the highly-visual candlestick chart, and found that people were pretty good with keeping track of what the pitches indicated. We also tested different methods of navigation, including a system of knobs to quickly traverse data. People were happy with this intuitive way of speeding up linear navigation. Both of these prototypes made it into our next stage of iterative design.
                </p>
            </div>
        </section>

        <section>
            <div class="col-sm-8 col-sm-offset-2">
                <h3>Takeaways from early prototypes</h3>
            </div>
        </section>
        <section>
            <div class="col-sm-8 col-sm-offset-2 newspaper">
                <p tabindex="0">
                    We had a lot of takeaways from our early design phase. Most notably, this stage was very useful because it helped us figure out which promising ideas would not be feasible. We had a strong notion that users would expect our systems to be very powerful. We also learned that people could do pretty well with identifying different sounds in terms of pitch or timbre. Finally, we learned that some technologies are simply not ready to handle the different interpretations people may have of a visualization.
                </p>
            </div>
        </section>
        <!--
        <section>
            <div class="col-sm-8 col-sm-offset-2">
                <h3>What we learned from early prototypes</h3>
                <p tabindex="0" class="newspaper">
                    Each prototype taught us something new. For example, we explored conversational user interfaces (CUIs). In this prototype, there was a big mismatch between what we felt we could provide (“what is the price of Google stock?”) and what users expected we could provide (“compare Apple and Google stock.”) Another promising prototype that subsequently fell into the infeasible category was generating crowdsourced or machine learning descriptions of charts. We learned that the technology isn’t really there, from an ML perspective, and that crowdsourcing won’t work well, especially when taking into account our research insight, “People who help me are interfaces, too.” There was simply no way to determine if a description was accurate. Finally, we explored touch-based interactions. We received very positive feedback about these prototypes, but upon exploring technical implementation, we realized that our examples were very basic, and the cost to provide dynamic, real-time tactile feedback would be prohibitively expensive. Not all of our prototypes were dead-ends, however. We explored using timbre to convey different values within the highly-visual candlestick chart, and found that people were pretty good with keeping track of what the timbres indicated. We also tested different methods of navigation, including a system of knobs to quickly traverse data. People were happy with this intuitive way of speeding up linear navigation. Both of these prototypes made it into our next stage of iterative design.
                </p>
            </div>
        </section>
-->

    </div>

    <div class="row sec-head" id="itdes">
        <div class="col-sm-8 col-sm-offset-2">
            <h2>Iterative Design</h2>

        </div>
    </div>



    <div class="row">
        <div>
            <div class="col-sm-8 col-sm-offset-2 ">
                <p tabindex="0" class="sec-subhead">By the end of our rapid prototyping, we had narrowed down to the medium of sound, the platform of desktop, and the financial task of analyzing security price charts to predict future price movements. While our earlier prototypes had explored aspects of sonification and navigation, it was time to prototype audio and control interactions within a cohesive system. Through our learnings from usability testing of different kinds of auditory output, navigation modes, and task flows, we arrived at the current iteration of Stockgrok.</p>
            </div>
        </div>
        <section>
            <div class="col-sm-8 col-sm-offset-2">
                <h3>Usability Testing</h3>
                <p class="newspaper">Earlier tests of navigation mode and audio cues with eight people with visual impairments helped us narrow down to a solution that used pitch, timbre, and earcon audio cues to provide access to data through keyboard controls. We used these findings to build and refine the higher fidelity Stockgrok prototype through usability tests with two more people with visual impairement. However, because they weren’t investment professionals, we also tested with two sighted domain experts to see if they could make investment decisions using Stockgrok through audio alone with access to the audio equivalent of visual cues used in charts.
                </p>
                <table class="rwd-table">
                    <tr>
                        <td></td>
                        <th scope="col">Navigation prototypes</th>
                        <th scope="col">Stockgrok system</th>
                    </tr>
                    <tr>
                        <th scope="row">People with visual impairments</th>
                        <td>8 users</td>
                        <td>2 users</td>
                    </tr>
                    <tr>
                        <th scope="row">Sighted finance domain experts</th>
                        <td>0 users</td>
                        <td>2 users</td>
                    </tr>
                </table>

            </div>


        </section>
        <section>
            <div class="col-sm-8 col-sm-offset-2">
                <h3>Navigation prototypes</h3>
                <p></p>
            </div>


        </section>
        <section>
            <div class="col-sm-8 col-sm-offset-2 newspaper3">
                <img src="img/design/keyboard.png" style="margin-top:0px !important;" alt="Stylized photograph of Bloomberg keyboard" class="img-responsive">
                <figcaption class="caption">Bloomberg Keyboard</figcaption>
                <img src="img/design/tablet.png" alt="Stock photograph of a hand holding a stylus up to a drawing tablet" class="img-responsive">
                <figcaption class="caption">USB Drawing Tablet and Stylus</figcaption>
                <img src="img/design/knob.png" alt="A palm-sized round knob with a blue border sits on a table" class="img-responsive">
                <figcaption class="caption">USB Powermate Knob</figcaption>
            </div>


        </section>
        <section>
            <div class="col-sm-8 col-sm-offset-2">
                <p>We tested three navigation modalities: scrubbing with a drawing table, a knob, and keyboard shortcuts to navigate our interfaces. The drawing tablet showed by far the lowest accuracy and lowest user-reported confidence and control. We tested an additional five people with visual impairments with the knob and keyboard. Knob and keyboard were very close on measures of accuracy and user-reported control and confidence. Drawing upon our insights, because the keyboard required no additional hardware and fit into existing finance workflows, we scoped to keyboard.

                </p>

            </div>


        </section>
        <section>
            <div class="col-sm-8 col-sm-offset-2">
                <h3>Sonification findings</h3>
                <p></p>
            </div>


        </section>

        <section>
            <div class="col-sm-8 col-sm-offset-2">
                <p>We tested several things with sound. We initially used stereo, playing pitch-mapped closing price values in one ear and earcons (audio icons) of two varieties in the other ear to indicate when a stock closed above or below a moving average. We thought stereo could serve as a way to communicate more auditory information at once. We found that users were able to easily pick out the earcon cues, and could do so even without needing both ears. Since requiring both ears cuts the user off from their surroundings, we decided that mono audio would be enough and enable users to multitask, for example listening to colleagues in one ear while using the audio interface at once.
                </p>
                <img src="img/headphones.jpeg" alt="Sony headphones in front of a laptop" class="img-responsive">
                <p> We were also interested to discover that users, particularly sighted users, struggled to understand relative pitches and distinguish timbres (qualities of sound). However, when making the timbres dramatically different, other users noticed the sounds were distractingly abrasive. As we iterated, we tweaked the sound design so that the timbres were more distinctive while also pleasing to the ear. In terms of pitch, we experimented with different pitch-mapping systems. Initially, the pitch had a very wide range so as to allow auditory perception of small changes in values. However, we found that very low and very high values became hard to hear. Not only that, but users still struggled to understand relative pitch values. Because of this, we narrowed the pitch range for all datasets.</p>
                <p>Despite variance in the abilities of users to distinguish sounds, think aloud comments and reflective interviews showed that the audio did serve to communicate high level trends, like a general upward price trend for a range. While confidence for using pitch alone was highly variable, when combined with the ability to get details on data with speech at any point, visually impaired users reported high confidence. </p>
            </div>


        </section>


    </div>



    <div class="row sec-head-end" id="stockgrok">
        <div class="col-sm-8 col-sm-offset-2">
            <h2>Stockgrok</h2>

        </div>
    </div>



    <div class="row">
        <div>
            <div class="col-sm-8 col-sm-offset-2">
                <p tabindex="0" class="sec-subhead">Our findings around sonification and navigation, synthesized with research and observations with finance specialists, guided us to build out the final features of Stockgrok. In order to evaluate its effectiveness, we tested it not just with people with visual impairments, but also with sighted finance experts. We wanted to see if people used to visual cues in stock charts could get the information they needed through audio alone while using Stockgrok without visuals.</p>
            </div>
        </div>
        <section>
            <div class="col-sm-8 col-sm-offset-2">
                <h3>Task</h3>
                <p>We presented users with the following task:</p>
                <p tabindex="0" class="newspaper sec-subhead2">
                    "Imagine you're trying to decide whether or not to buy or sell a stock. Use Stockgrok to explore the data and tell us what you observe."
                </p>
                <p>
                    After using Stokgrok without visuals, we asked sighted domain experts to draw the simple moving average and price lines. Pictured below are two sketches experts drew. After a few minutes of training, both sighted experts were able to easily observed the overall upward price trend. Second, both experts also mentioned and drew out the major cross in November, using it as a cue that signaled a new trend. Third, both experts remarked on the jump in magnitude at the end.
                </p>
                <p>
                    As one user clicked through the days, he described the mental image of drawing the two lines in his head: “I can [mentally] draw this out: higher, higher, higher, higher, way extended above the 50 day.” 
                </p>
            </div>
        </section>

        <section>
            <div class="col-sm-8 col-sm-offset-2 newspaper-col">
                <img src="img/m12-sketch-only.png" style="margin-top:0px !important;" alt="Sighted user sketch of a chart" class="img-responsive">
                <figcaption class="caption">A sighted finance specialist correctly recreates both axes, the general trend of both price and SMA lines and cross. </figcaption>
                <img src="img/product/m10-simple-full.png" alt="Sighted user sketch of a chart" class="img-responsive">
                                <figcaption class="caption">A sighted finance specialist recreates the general trend of both price and SMA lines, cross, and jump in price. </figcaption>

            </div>

        </section>
        <section>
            <div class="col-sm-8 col-sm-offset-2">
               <p> We also tested with people with visual impairments who had some previous experience with finance and data. We walked them through the features and concepts of the prototypes. They caught on quickly. Reactions were overwhelmingly positive. They were able to identify many of the same cues as finance experts, such as cross points that signaled a new trend.</p>
               <p>One user said: “I can almost see the data by hearing it. It would just take exponentially more time to analyze the data [with a table].”</p>
               <p>Overall, these tests validated that experts were able to access the key cues relevant to investment decisions, and people with visual impairments were able to confidently access information from visualizations that was previously inaccessible.</p>
                <a class="cta" href="https://stockgrok.github.io/prototype" target="_blank"><img src="img/browser-mock2.png" alt="Screenshot of Stockgrok home page" class="img-responsive" style="box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);"></a>
            <p><a class="cta" href="https://stockgrok.github.io/prototype" target="_blank">Try Stockgrok for yourself.</a></p>
            </div>

        </section>
        <section>
            <div class="col-sm-8 col-sm-offset-2" style="margin-top: 40px">
                <a href="#content">
                    <p><i class="glyphicon glyphicon-chevron-up"></i> Back to Top</p>
                </a>
            </div>
        </section>

    </div>




</body>




<footer role="contentinfo">
    <div class="row">
        <div class="col-sm-1 col-sm-offset-2">
            <p>Team b7g</p>
        </div>
        <div class="col-sm-7">
            <p>We are a team of five Carnegie Mellon University Master’s of Human Computer Interaction students. We have been working with Bloomberg, LP to help make financial visualizations more accessible to people with visual impairments. This product is the culmination of eight months of research and design.</p>
        </div>
    </div>
    <div class="row">
        <div class="col-sm-1 col-sm-offset-2">
            <p>Sponsors</p>
        </div>
        <div class="col-sm-7">
            <p>Bloomberg LP, Carnegie Mellon University</p>
        </div>
    </div>
    <div class="row">
    
        <div class="col-sm-1 col-sm-offset-2">
            <p>Copyright</p>
        </div>
        <div class="col-sm-7">
            <p>&copy; 2017  Team b7g | HCII</p>
        </div>

    </div>

    <!-- jQuery -->

</footer>

</html>